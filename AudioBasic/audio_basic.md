
### 0x00 开篇
2020注定是不平凡的一年，新冠病毒给每个行业都带来了大量的冲击和变革，很多传统行业受到了严重打击，全球倒闭或破产的中小微企业数不胜数，这是全人类的一次危机。

危机危机，让我们重新拆解认识一下这个词，危机等于危险加机遇。当变革来临时，往往都是风险与机遇并存，这次疫情对一部分行业来说或是一场灾难，但对另外一些行业却是一次千载难逢的机遇。视频会议，协同办公，在线教育等产品以极低的获客成本在短时间内获取了海量的用户，国内外的互联网巨头也都纷纷争相布局进入这些市场，竞争也变得白热化，大的玩家进入也大大加速了市场对产品品类的认知，大幅缩短了市场培育周期。

举个例子，停学不停课期间，几乎每个老师和学生都熟悉了在线教育这种教学形态；这届本科生、研究生和博士生毕业班的云答辩几乎都使用了视频会议系统(譬如腾讯会议)，学生和老师都在短时间内认识并掌握了视频会议这种产品形态。人的习惯一旦养成，在很长一段时间内都会刻在骨子里，就像现在我回家的第一件事就是使用硫磺皂去洗手，所以即便是未来疫情结束，这种习惯和认知也会保留下来。

再来看两则非常有有代表性的新闻。
1. 2020年5月22日，Facebook继Twiter、Square、Coinbase和Shopify之后，未来允许员工永久在家办公。
![永久远程办公](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTwblOnGfFR6dPdt6EcIFrZPBMQZ9pLawAd6q9bNRzoS1RBiaA3ovjMFw/0?wx_fmt=png)
2. 2020年4月2日消息，据外媒报道，视频会议软件提供商Zoom公司CEO于美国当地时间周三表示，视频会议应用Zoom的日活跃用户已经超过2亿人，与去年年底相比翻了20倍(去年同期的日活数据约1000W)。

远程协同办公一直是未来的大趋势，这次疫情只不过是催化剂，大大加速了这一进程。我们不妨畅想一下未来10年，科技类公司会有百分之80到90的员工都可以高效率地进行远程协同办公，这里面免不了要有一些人与人之间的沟通，从产品角度考虑，视频会议系统是理所当然的解决方案。

从技术角度考虑，在线教育、视频会议、直播都离不开两个关键的技术：计算机网络和音视频。 5G高速网络未来将整个世界更快速地连接在一起，音视频让人与人见屏如面，下个时代我称之为”5G音视频+“时代，在这个时代，音视频+5G会有越来越多的玩法。

谈完了对未来美好的想象，让我们再回到当下，脚踏实地一步步打好技术基础。这两个月我陆续梳理和总结了过去4年的音视频知识学习和项目经验，准备以系列博客的形式陆续分享出来。文章会侧重分享一些音视频领域的基础理论和思考，以及移动端的音视频编解码和传输优化实践。

本篇文章是系列博客的第一篇，主要分享数字世界中声音的基本表征方法，这些也是音频编解码，音频处理等的基础。

### 0x01 什么是声音？
在高中和大学的物理学中，相信我们都学习到了声音的基本定义，在这里让我们回到教室，一起回顾和温习下考试范围。
**声音的物理学定义：声音是振动产生的声波，通过介质（气体、固体、液体等）传播并能被人或动物听觉器官所感知的波动现象。**
从上面的定义中，可以得到声音的三个基本概念：
1. 物体震动产生声波;
2. 声音的传播本质是声波的传播;
3. 声波被人或其他动物的听觉器官所感知，称为声音。

### 0x02 声音的表征方法
从上面声音的物理学定义中得知，声音本质是自然界中的声波，所以对声音的表征可以约等价于对声波的表征。在正式介绍声音的表征之前，我们先来认识一位伟大的数学家和物理学家：傅里叶。
![傅里叶](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zT3mOmyMNytAx0Z4USBltCwibKpeZZxgqh3ZwX6F89kYwic2GGicYLNA8jg/0?wx_fmt=png)

傅立叶是一位法国数学家和物理学家的名字(Jean Baptiste Joseph Fourier(1768-1830)), 傅里叶于1807年在法国科学学会上发表了一篇论文，运用正弦曲线来描述温度分布，论文里有个在当时颇具争议性的命题：任何连续周期信号可以由一组适当的正弦曲线组合而成。当时审查这个论文的人，其中有两位是历史上著名的数学家拉格朗日和拉普拉斯，当拉普拉斯和其他审查者投票通过并要发表这个论文时，拉格朗日坚决反对，直到拉格朗日死后15年这个论文才被发表出来。伟大的人也都经历了比平常人更多的磨难，致敬。

根据傅里叶原理，任何信号都可以表达成简单信号的叠加，声波也是一种信号，因而声波也可以表征为不同频率和相位的简单正弦波复合叠加。既然是一种波，那么我们就可以用频率，振幅等物理概念来描述声音。

#### 2.1 时域和频域
从上文得知，声波可以表征为不同频率和相位的简单正弦波复合叠加。对于信号分析，经常使用的有波形图和频谱图，分别对应时域和频域分析。
1. 波形图：信号在时间轴随时间变化的总体概括，横坐标是时间，波形是连续的时域信号。
2. 频谱图：通过对波形进行傅里叶变换，把波形中的每个频率拆开来，再在纵轴上展开，横坐标是频率。频谱图是离散的频域信号，是三维的，越亮表示在这个频率上越响，越暗表示越弱。
![时域和频域](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTVficaAk2UvGj8akzgNAf1v7squicrTbkvdkPQLO3O5spT86BRpmk5W7g/0?wx_fmt=png)

频谱图相对于波形图，是包含有更多信息的，唯一的缺点就是无法表示整体音量总和的大小，所以一般和波形配合观看。

让我们看一个实际的音频文件分析得到的波形图和频谱图。
![波形图](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTgKicJicxotSuiaAZG69jIISAFjbszrXy2N1MB5dqcKmvn0Y2QWwnGanZg/0?wx_fmt=png)
![频谱图](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTAxtgiczw7Mw5cmiarrzgHe5VfiaxtibEMeTNsibbaqC8ZPw1F2qaDlyTwkQ/0?wx_fmt=png)

#### 2.2 模数转换
自然界中的声音是连续的模拟信号，而计算机中能处理的是离散的数字信号，因而声音数字表征的第一步就是要将模拟信号转换为数字信号。这里就会使用到脉冲编码调制（英语：Pulse-code modulation，缩写：PCM），PCM就是把一个时间连续，取值连续的模拟信号变换成时间离散，取值离散的数字信号后在信道中传输。简而言之PCM就是对模拟信号先抽样，再对样值幅度量化，编码的过程(如下图)。
![PCM](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTrPfyJU6eP17NkYNZEFTH45cSWrKBevT4oiaGZRaAGcJPX3RMicmYICmA/0?wx_fmt=png)
对于音频来说，PCM就是原始的未压缩的音频编码格式。相对自然界的连续声音信号，数字世界中任何音频编码都是有损的，在计算机应用中，能达到高保真的就是PCM编码，因而PCM被约定为无损编码，对应的譬如MP3则属于有损编码。

#### 2.3 采样率
采样率(Sampling Rate，又称采样频率，音频帧率)，是指单位时间内样本数，是采样周期的倒数，单位是Hz, 对应PCM的采样阶段。

例如常见的采样频率有8kHz、16kHz, 44.1kHz, 48kHz。采样率的大小影响到声音的质量，显然，采样率越高，量化后的波形越接近原始波形，声音的质量越高，而需要的存储空间也会越多，采样率越低，声音的质量越低，需要的存储空间想相对越少。

根据奈奎斯特–香农采样定理，采样频率必须至少是信号中最大频率的两倍，才可以从信号采样中恢复原始信号。人耳的类听觉范围为20-20000Hz，那么数字音频采样率至少40KkHz才能恢复原始信号（CD音频使用44100Hz的采样率，部分原因也在于此）。

关于业务场景中采样频率的选择，这里有一个参考。人耳感知范围20Hz~20kHz被划分成四个频宽类别：窄带、宽带、超宽带和全带。
![采样率划分](https://mmbiz.qpic.cn/mmbiz_jpg/aDo39awklGqc38gbfnxMibciaOBkqzr6zT6vMbFHKOpzz1JzkLwdeSvjZY3QiaEcSWMvVibBBzXX3C7gUaW9fGxyNg/0?wx_fmt=jpeg)
**窄带（narrowband）**
普通电话所覆盖的频宽，从300Hz到3.4kHz，对应采样率6.8kHz。普通电话的采样率是8kHz，对应频宽 4kHz，对于人声语音是足够的。
**宽带（wideband）**
从50Hz到7kHz的频宽，对应采样率14kHz，可以很好地捕捉和还原人声，然而对于音乐声还是不够的。这是在人声语音通话场景下的所谓高清语音。
**超宽带（super-Wideband）**
从 50Hz到14kHz，对应采样率28kHz，基本可以覆盖人声和音乐声，对于非专业音乐人的用户来说，不管是人声通话还是音乐直播，这样的频宽都是足够的。
**全带（fullband）**
从20Hz到20kHz，对应40kHz采样率，全面覆盖人类的听觉范围，能够满足音乐发烧友或者专业音乐人的需求。超过40KHz都可以称作全带语音。CD的采样率就是44.1kHz。

所以，如果你的业务场景是识别人声，譬如语音通话，录制微课，基本采用16kHz就可以很好的还原了；如果你需要传屏录制系统播放的音乐声，那么就需要使用44.1kHz的采样率。

#### 2.4 位深(采样深度，量化深度)
位深表示一个样本的二进制的位数，即每个采样点用多少比特表示，对应量化阶段。

在计算机中音频的位深(量化深度)常见的有8、16、32位（bit）等。例如：位深为8时，每个采样点可以表示256个不同的量化值，而位深为16时,每个采样点可以表示65536个不同的量化值。量化深度的大小影响到声音的质量，显然，位数越多，量化后的波形越接近原始波形，声音的质量越高，而需要的存储空间也越多，位数越少，声音的质量越低，需要的存储空间越少。

位深除了表征用多少个二进制位表示一个采样，这里还会涉及到有符号数和无符号数的问题，大端存储和小端存储的字节序问题，整形和浮点型问题。例如用2个字节表示的样本数据，有符号的话表示范围为-32768~32767，无符号就是0~65535；大多数格式的PCM样本数据使用整形表示，然而在一些对精度要求高的应用方面，会使用浮点类型表示PCM样本数据。

在ffmpeg处理音频时，经常会看到类似f32be、s16le、u16be等字符串，这些字符串其实就是表征位深的上述几个概念，例如：s16le，就表示一个样本用16bit有符号的整形数据表示，存储字节序为小端。使用ffmpeg -formats命令，可以看到ffmpeg支持的所有音视频格式。

由于指定长度的二进制位数能表示的范围空间有限，当要表征的音频范围超过了这个二进制数据能表示的范围后，数据就会溢出。所以在音频放大时，有个基本的溢出保护问题。例如PCM signed 16-bit little-endian的音频，每个样本2个字节，每个样本的取值空间-32768 ~ 32767，放大后的音频超过这个区间时，就会产生溢出，严重时会产生破音，因此在实现软件音频放大时，要进行基本的溢出保护。

```c
//线性放大音频2倍
int16_t pcm[1024] = read pcm from file or network;
int32_t val;
for (idx = 0; idx < 1024; idx++) {
    val = pcm[idx] * 2;
    val = val > 32767 ? 32767 : val;
    val = val < -32768 ? -32768 : val
    pcm[idx] = val
}
```

#### 2.5 声道数
记录声音时，如果每次生成一个声波数据，称为单声道；每次生成两个声波数据，称为双声道。使用双声道记录声音，能够在一定程度上再现声音的方位，反映人耳的听觉特性。
对于双声道数，在音频存储时有个非常容易导致错误的概念：交错存储和非交错存储。
1. 交错存储：左右声道依次存储
2. 非交错存储: 先存储全部左声道，再存储全部右声道 （Planar）

![交错与非交错](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTtia7VbGLpsmM2R8OKc06iax8fOessEaYpuTjDLCtEwOCyibrhFvicTBOZg/0?wx_fmt=png)
理解这两个概念，对读取和操作音频数据非常重要，例如从iOS系统的AudioBufferList结构体中读取双声道数据时，必须首先弄清楚左右声道的数据在这个结构体里分别是怎么存储的。

PS：与视频中YUV存储中的交错存储与非交错存储的概念一样。

#### 2.6 码率
音频的码率又称为比特率，是指音频数据每秒钟的比特位个数，单位通常用kbps表示。
对于原始的PCM数据来说，码率是可以通过采样率，位深和声道数直接计算出来的。
```
PCM码率 = 采样率 * 声道数 * 位深 (Kbps)
```

因此一个确定时长的PCM文件大小，也是可以直接计算出来的。
```
PCM文件大小（Byte）= 采样频率（Hz）× 声道数 ×（位深/8）× 时长
```

例如，16KHz,单声道的PCM音频，1个小时的文件大小为：
16000 * 1 * 16 / 8 * 3600 = 115200000 byte = 109.86MB

PS: MP3、AAC等压缩音频格式，其码率通常由编码器指定，一般无法通过采样率和位深直接计算得到。

#### 2.7 压缩编码
从上面PCM音频文件的大小计算可以看到，数字音频信号如果不加压缩地直接进行传送或者存储，将会占用极大的带宽以及磁盘空间，因而音频数据通常会进行压缩，以便更易于存储和传输。

通过采样以及量化得到的数字音频信号中存在着大量冗余。数字音频压缩编码保证信号在听觉方面不产生失真的前提下，对音频数据信号进行尽可能大的压缩。数字音频压缩编码采取去除声音信号中冗余成分的方法来实现。所谓冗余成分指的是音频中不能被人耳感知到的信号，它们对确定声音的音色，音调等信息没有任何的帮助。冗余信号包含人耳听觉范围外的音频信号以及被掩蔽掉的音频信号等。例如，人耳所能察觉的声音信号的频率范围为20Hz～20KHz，范围外的其它频率人耳无法察觉，都可视为冗余信号。此外，根据人耳听觉的生理和心理声学现象，当一个强音信号与一个弱音信号同时存在时，弱音信号将被强音信号所掩蔽而听不见，这样弱音信号就可以视为冗余信号而不用传送。这就是人耳听觉的掩蔽效应。

**有损压缩与无损压缩**
无损压缩。无损压缩虽然缩小音频的储存大小，但可以保留原始文件的所有信息。无损压缩是一个可逆的过程，利用信息冗余进行数据压缩，类似我们平时用的rar，zip等文件压缩。常见无损压缩格式有：APE，FLAC等。
有损压缩。有损压缩是一个不可逆的过程。有损数据压缩利用人类听觉特性，将不重要的声音信息舍弃，虽然有损压缩在理论上对原始文件造成损失，但这种损失不一定能被人耳分辨出来。常见有损压缩格式有:MP3，AAC等。

#### 2.8 Frame和Packet
Frame: 代表一个音频帧，对应一个采样
Packet：代表一个或一组音频帧(一般映射压缩格式)
![Frame和Packet](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTdCadj55p4t3IbILhTFXRJvvSPf8qp80k8jNA8xJrh4lAVXdSV4wR0g/0?wx_fmt=png)

音频的编码过程，可以理解为从Frane -> Packet的表征过程。
音频的解码过程，可以理解为从Packet -> Frame的表征过程。

熟悉FFmpeg的同学应该对AVFrame和AVPacket这两个结构体非常熟悉，在FFmpeg中，
AVPacket是用于存储解码前数据(编码数据:H264/AAC等)，AVFrame是用于存储解码后数据(像素数据:YUV/RGB/PCM等)。

### 0x03 小结
最后，用两张图总结一些数字世界中声音的表征方法，来结束本篇分享。
![小结1](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTfI1F33TuztWCh2bNNEibiagFDdu4I5LrpLOzDoMLiaVwhjCDaBiag5PTVw/0?wx_fmt=png)
![小结2](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGqc38gbfnxMibciaOBkqzr6zTR78icbZHkJgqo8jUnmarfydRvG4ic5KPRo9qYicjVjuiaqIxHCtjbAicKtw/0?wx_fmt=png)


### 欢迎大家到我的公众号留言交流
![公众号](https://mmbiz.qpic.cn/mmbiz_png/aDo39awklGpc45I80p0s8n1okrGkOT1mnicMFxuUGRh0icyicLyEquLzJCKoAKdcr7tNPQfpwYMGhCVUE1YQ58OmA/0?wx_fmt=png)




